# Copyright (c) Meta Platforms, Inc. and affiliates.
# All rights reserved.

# This source code is licensed under the license found in the
# LICENSE file in the root directory of this source tree.

import logging
import math
from typing import Callable, Iterable, List, Optional, Sequence

import torch

from torch.utils.data import BatchSampler, DataLoader, Dataset, IterableDataset, Subset

from torch.utils.data.distributed import DistributedSampler



class TorchTrainMixedDataset:
    def __init__(
        self,
        datasets: List[Dataset],
        batch_sizes: List[int],
        num_workers: int,
        shuffle: bool,
        pin_memory: bool,
        drop_last: bool,
        collate_fn: Optional[Callable] = None,
        worker_init_fn: Optional[Callable] = None,
        phases_per_epoch: int = 1,
        dataset_prob: Optional[List[float]] = None,
    ) -> None:
        
        """
            Args:
                datasets (List[Dataset]): List of Datasets to be mixed.
                batch_sizes (List[int]): Batch sizes for each dataset in the list.
                num_workers (int): Number of workers per dataloader.
                shuffle (bool): Whether or not to shuffle data.
                pin_memory (bool): If True, use pinned memory when loading tensors from disk.
                drop_last (bool): Whether or not to drop the last batch of data.
                collate_fn (Callable): Function to merge a list of samples into a mini-batch.
                worker_init_fn (Callable): Function to init each dataloader worker.
                phases_per_epoch (int): Number of phases per epoch.
                dataset_prob (List[float]): Probability of choosing the dataloader to sample from. Should sum to 1.0
        """

        self.datasets = datasets
        self.batch_sizes = batch_sizes
        self.num_workers = num_workers
        self.shuffle = shuffle
        self.pin_memory = pin_memory
        self.drop_last = drop_last
        self.collate_fn = collate_fn
        self.worker_init_fn = worker_init_fn
        assert len(self.datasets) > 0
        for dataset in self.datasets:
            assert not isinstance(dataset, IterableDataset), "Not supported"
            # `RepeatFactorWrapper` requires calling set_epoch first to get its length
            self._set_dataset_epoch(dataset, 0)
        self.phases_per_epoch = phases_per_epoch
        self.chunks = [None] * len(datasets)
        if dataset_prob is None:
            # If not provided, assign each dataset a probability proportional to its length.
            dataset_lens = [
                (math.floor(len(d) / bs) if drop_last else math.ceil(len(d) / bs))
                for d, bs in zip(datasets, batch_sizes)
            ]
            total_len = sum(dataset_lens)
            dataset_prob = torch.tensor([d_len / total_len for d_len in dataset_lens])
        else:
            assert len(dataset_prob) == len(datasets)
            dataset_prob = torch.tensor(dataset_prob)

        logging.info(f"Dataset mixing probabilities: {dataset_prob.tolist()}")
        assert dataset_prob.sum().item() == 1.0, "Probabilities should sum to 1.0"
        self.dataset_prob = dataset_prob

    def _set_dataset_epoch(self, dataset, epoch: int) -> None:
        if hasattr(dataset, "epoch"):
            dataset.epoch = epoch
        if hasattr(dataset, "set_epoch"):
            dataset.set_epoch(epoch)

    def get_loader(self, epoch) -> Iterable:
        # ######################## jimin ########################
        # ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµ ì‚¬ìš© ì—¬ë¶€ ìŠ¤ìœ„ì¹˜ (True: ë‹¨ê³„ë³„ í•™ìŠµ, False: ì²˜ìŒë¶€í„° ì „ì²´ ë¹„ë””ì˜¤ í•™ìŠµ)
        temporalVideo = False 
        # #######################################################

        dataloaders = []
        for d_idx, (dataset, batch_size) in enumerate(
            zip(self.datasets, self.batch_sizes)
        ):
            # [ë‹¨ê³„ 1] ì»¤ë¦¬í˜ëŸ¼ í•™ìŠµì„ ì‚¬ìš©í•  ê²½ìš° (ê¸°ì¡´ ë¡œì§)
            if temporalVideo and self.phases_per_epoch > 1:
                main_epoch = epoch // self.phases_per_epoch
                local_phase = epoch % self.phases_per_epoch

                if local_phase == 0 or self.chunks[d_idx] is None:
                    self._set_dataset_epoch(dataset, main_epoch)
                    g = torch.Generator()
                    g.manual_seed(main_epoch)
                    self.chunks[d_idx] = torch.chunk(
                        torch.randperm(len(dataset), generator=g),
                        self.phases_per_epoch,
                    )
                dataset = Subset(dataset, self.chunks[d_idx][local_phase])
            
            # [ë‹¨ê³„ 2] ì»¤ë¦¬í˜ëŸ¼ì„ ê»ê±°ë‚˜, ì²˜ìŒë¶€í„° ì „ì²´ ë°ì´í„°ë¥¼ ì“¸ ê²½ìš°
            else:
                self._set_dataset_epoch(dataset, epoch)
                # ######################## jimin ########################
                # ì»¤ë¦¬í˜ëŸ¼ì„ ëˆ ê²½ìš°, ë°ì´í„°ì…‹ ë‚´ë¶€ì˜ stageë¥¼ ê°•ì œë¡œ 'full'ë¡œ ê³ ì •í•©ë‹ˆë‹¤.
                if hasattr(dataset, "stage"):
                    dataset.stage = "full"
                    logging.info(f"âš ï¸ [Curriculum Bypass] Stage forced to FULL for dataset {d_idx}")
                # #######################################################

            # ì´í›„ ìƒ˜í”ŒëŸ¬ ë° ë¡œë” ì„¤ì •ì€ ë™ì¼í•˜ê²Œ ìœ ì§€
            sampler = DistributedSampler(dataset, shuffle=self.shuffle)
            sampler.set_epoch(epoch)

            batch_sampler = BatchSampler(sampler, batch_size, drop_last=self.drop_last)
            dataloaders.append(
                DataLoader(
                    dataset,
                    num_workers=self.num_workers,
                    pin_memory=self.pin_memory,
                    batch_sampler=batch_sampler,
                    collate_fn=self.collate_fn,
                    worker_init_fn=self.worker_init_fn,
                )
            )
        return MixedDataLoader(dataloaders, self.dataset_prob)





class MixedDataLoader:
    def __init__(self, dataloaders, dataset_prob):
        self.dataloaders = dataloaders
        # ì¤‘ìš”: self.dataset_probë¡œ í• ë‹¹í•´ì•¼ __iter__ì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        self.dataset_prob = dataset_prob

    def __iter__(self):
        # ê° ë°ì´í„°ì…‹ì˜ ì´í„°ë ˆì´í„° ìƒì„±
        iters = [iter(loader) for loader in self.dataloaders]
        while True:
            # ì„¤ì •ëœ í™•ë¥ (dataset_prob)ì— ë”°ë¼ ë°ì´í„°ì…‹ ì¸ë±ìŠ¤ ì„ íƒ
            try:
                d_idx = torch.multinomial(self.dataset_prob, 1).item()
                yield next(iters[d_idx])
            except StopIteration:
                # í•˜ë‚˜ë¼ë„ ë°ì´í„°ì…‹ì´ ì†Œì§„ë˜ë©´ ì¢…ë£Œ
                break
            except Exception as e:
                # ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë¡œê¹…
                logging.error(f"Error during iteration: {e}")
                break

    def __len__(self):
        return sum(len(loader) for loader in self.dataloaders)

    def __iter__(self):
        # ê° ë°ì´í„°ì…‹ì˜ ì´í„°ë ˆì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        iters = [iter(loader) for loader in self.dataloaders]
        while True:
            # ì„¤ì •ëœ í™•ë¥ (dataset_prob)ì— ë”°ë¼ ì–´ë–¤ ë°ì´í„°ì…‹ì—ì„œ ë°°ì¹˜ë¥¼ ê°€ì ¸ì˜¬ì§€ ê²°ì •í•©ë‹ˆë‹¤.
            d_idx = torch.multinomial(self.dataset_prob, 1).item()
            try:
                yield next(iters[d_idx])
            except StopIteration:
                # í•˜ë‚˜ë¼ë„ ë°ì´í„°ì…‹ì´ ëë‚˜ë©´ ë°˜ë³µì„ ì¢…ë£Œí•©ë‹ˆë‹¤.
                break

    def __next__(self):
        """
        Sample a dataloader to sample from based on mixing probabilities. If one of the dataloaders is exhausted, we continue sampling from the other loaders until all are exhausted.
        """
        if self._iter_dls is None:
            raise TypeError(f"{type(self).__name__} object is not an iterator")

        while self._iter_mixing_prob.any():  # at least one D-Loader with non-zero prob.
            dataset_idx = self._iter_mixing_prob.multinomial(
                1, generator=self.random_generator
            ).item()
            try:
                item = next(self._iter_dls[dataset_idx])
                return item
            except StopIteration:
                # No more iterations for this dataset, set it's mixing probability to zero and try again.
                self._iter_mixing_prob[dataset_idx] = 0
            except Exception as e:
                # log and raise any other unexpected error.
                logging.error(e)
                raise e

        # Exhausted all iterators
        raise StopIteration


######################## jimin ########################
import numpy as np
import torch
import torch.nn.functional as F
import pywt
from typing import Dict, List, Optional
import logging

class FAP_CLDataset(Dataset):
    """
    Frequency-Aware Progressive Curriculum Learning for Medical Ultrasound Video
    IEEE SPL-style innovation: Signal processing perspective in curriculum learning
    """
    
    def __init__(
        self,
        folder: str,
        milestones: Dict[str, int],
        wavelet_type: str = 'db4',
        freq_bands: List[str] = ['LL', 'LH', 'HL', 'HH'],  # Wavelet subbands
        curriculum_schedule: str = 'low_to_high',  # 'low_to_high' or 'hybrid'
        **kwargs
    ):
        """
        Args:
            folder: ë°ì´í„° í´ë” ê²½ë¡œ
            milestones: {'dense': 0, 'expand': 20, 'full': 50} ê°™ì€ curriculum ë‹¨ê³„
            wavelet_type: ì‚¬ìš©í•  wavelet ì¢…ë¥˜ ('haar', 'db4', 'sym4' ë“±)
            freq_bands: ì‚¬ìš©í•  ì£¼íŒŒìˆ˜ ëŒ€ì—­
            curriculum_schedule: ì €ì£¼íŒŒ â†’ ê³ ì£¼íŒŒ or hybrid í•™ìŠµ ì „ëµ
        """
        self.base_folder = folder
        self.milestones = milestones
        self.wavelet_type = wavelet_type
        self.freq_bands = freq_bands
        self.curriculum_schedule = curriculum_schedule
        
        # í˜„ì¬ ë‹¨ê³„ì™€ í•„í„°ë§ëœ ìƒ˜í”Œë“¤
        self.stage = "dense"
        self.current_freq_weights = self._get_freq_weights(self.stage)
        self.samples = []
        
        # FFT ê¸°ë°˜ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ì €ì¥
        self.freq_features = {}  # ë¹„ë””ì˜¤ë³„ ì£¼íŒŒìˆ˜ íŠ¹ì§• ì €ì¥
        
        self._load_and_analyze_data()
        
        logging.info(f"âœ… [SignalCurriculum] Stage: {self.stage.upper()} | "
                    f"Freq weights: {self.current_freq_weights} | "
                    f"Samples: {len(self.samples)}")
    
    def _get_freq_weights(self, stage: str) -> Dict[str, float]:
        """ë‹¨ê³„ë³„ ì£¼íŒŒìˆ˜ ëŒ€ì—­ ê°€ì¤‘ì¹˜ í• ë‹¹"""
        if stage == "dense":
            # ì´ˆê¸°: ì €ì£¼íŒŒ(Low-Low) ê°•ì¡°
            return {'LL': 1.0, 'LH': 0.3, 'HL': 0.3, 'HH': 0.1}
        elif stage == "expand":
            # ì¤‘ê°„: ì¤‘ê°„ ì£¼íŒŒìˆ˜ ì¶”ê°€
            return {'LL': 0.7, 'LH': 0.8, 'HL': 0.8, 'HH': 0.4}
        elif stage == "full":
            # í›„ê¸°: ëª¨ë“  ì£¼íŒŒìˆ˜ ê· ë“±
            return {'LL': 0.6, 'LH': 0.9, 'HL': 0.9, 'HH': 0.8}
        else:
            return {'LL': 1.0, 'LH': 1.0, 'HL': 1.0, 'HH': 1.0}
    
    def _analyze_video_frequency(self, npz_path: str) -> Dict:
        """ë¹„ë””ì˜¤ì˜ ì£¼íŒŒìˆ˜ íŠ¹ì§• ë¶„ì„ (Wavelet Transform ì‚¬ìš©)"""
        try:
            data = np.load(npz_path, allow_pickle=True)
            imgs = data['imgs']  # (T, H, W, 3) or (T, H, W)
            
            # ì²« ë²ˆì§¸ í”„ë ˆì„ë§Œ ë¶„ì„ (ëŒ€í‘œì„±)
            if imgs.ndim == 4:
                frame = imgs[0, :, :, 0]  # ì²« ì±„ë„ ì‚¬ìš©
            else:
                frame = imgs[0]
            
            # Wavelet Transformìœ¼ë¡œ ì£¼íŒŒìˆ˜ ëŒ€ì—­ ë¶„í•´
            coeffs = pywt.dwt2(frame, self.wavelet_type)
            LL, (LH, HL, HH) = coeffs
            
            # ê° ëŒ€ì—­ì˜ ì—ë„ˆì§€ ê³„ì‚°
            energies = {
                'LL': np.mean(np.abs(LL)),
                'LH': np.mean(np.abs(LH)),
                'HL': np.mean(np.abs(HL)),
                'HH': np.mean(np.abs(HH))
            }
            
            # ëŒ€ì—­ë³„ ì—”íŠ¸ë¡œí”¼ (ë³µì¡ë„ ì¸¡ì •)
            entropies = {}
            for band_name, band_data in zip(['LL', 'LH', 'HL', 'HH'], [LL, LH, HL, HH]):
                hist, _ = np.histogram(band_data.flatten(), bins=32)
                prob = hist / hist.sum()
                entropies[f'entropy_{band_name}'] = -np.sum(prob * np.log(prob + 1e-10))
            
            return {**energies, **entropies}
        except Exception as e:
            logging.warning(f"Frequency analysis failed for {npz_path}: {e}")
            return {band: 1.0 for band in self.freq_bands}
    
    def _load_and_analyze_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì£¼íŒŒìˆ˜ ë¶„ì„"""
        self.target_path = os.path.join(self.base_folder, self.stage, "uterine_niche")
        
        if not os.path.exists(self.target_path):
            self.target_path = os.path.join(self.base_folder, self.stage)
        
        if not os.path.exists(self.target_path):
            self.samples = []
            return
        
        # ëª¨ë“  NPZ íŒŒì¼ ìˆ˜ì§‘
        all_samples = sorted([f for f in os.listdir(self.target_path) if f.endswith('.npz')])
        
        # ì£¼íŒŒìˆ˜ íŠ¹ì§• ë¶„ì„ ë° ìƒ˜í”Œ í•„í„°ë§
        filtered_samples = []
        self.freq_features.clear()
        
        for sample in all_samples:
            npz_path = os.path.join(self.target_path, sample)
            
            # ì£¼íŒŒìˆ˜ íŠ¹ì§• ë¶„ì„
            freq_feats = self._analyze_video_frequency(npz_path)
            self.freq_features[sample] = freq_feats
            
            # í˜„ì¬ curriculum ë‹¨ê³„ì— ë§ëŠ” ìƒ˜í”Œì¸ì§€ í‰ê°€
            if self._should_include_sample(freq_feats):
                filtered_samples.append(sample)
        
        self.samples = filtered_samples
        
        # ìƒ˜í”Œë³„ ì¤‘ìš”ë„ ê°€ì¤‘ì¹˜ í• ë‹¹ (ì„ íƒì )
        self.sample_weights = self._compute_sample_weights()
    
    def _should_include_sample(self, freq_feats: Dict) -> bool:
        """ì£¼íŒŒìˆ˜ íŠ¹ì§• ê¸°ë°˜ ìƒ˜í”Œ í•„í„°ë§"""
        # ì˜ˆ: ì´ˆê¸° ë‹¨ê³„ì—ì„œëŠ” ê³ ì£¼íŒŒ ë…¸ì´ì¦ˆê°€ ë§ì€ ìƒ˜í”Œ ì œì™¸
        if self.stage == "dense":
            # ì €ì£¼íŒŒ ëŒ€ë¹„ ê³ ì£¼íŒŒ ì—ë„ˆì§€ ë¹„ìœ¨ì´ ë‚®ì€ ìƒ˜í”Œ ì„ í˜¸
            low_freq_energy = freq_feats.get('LL', 1.0)
            high_freq_energy = freq_feats.get('HH', 0.1)
            return (high_freq_energy / (low_freq_energy + 1e-10)) < 0.3
        
        elif self.stage == "expand":
            # ì¤‘ê°„ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì´ ì¶©ë¶„íˆ ìˆëŠ” ìƒ˜í”Œ ì„ í˜¸
            mid_freq_energy = (freq_feats.get('LH', 0) + freq_feats.get('HL', 0)) / 2
            return mid_freq_energy > 0.2
        
        else:  # full stage
            return True  # ëª¨ë“  ìƒ˜í”Œ í¬í•¨
    
    def _compute_sample_weights(self) -> Dict[str, float]:
        """ìƒ˜í”Œë³„ í•™ìŠµ ê°€ì¤‘ì¹˜ ê³„ì‚° (ì„ íƒì  ìƒ˜í”Œë§ìš©)"""
        weights = {}
        for sample in self.samples:
            feats = self.freq_features.get(sample, {})
            
            # ê°€ì¤‘ì¹˜ = í˜„ì¬ ë‹¨ê³„ì—ì„œ ì¤‘ìš”ë„ ë†’ì€ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì˜ ê°•ë„
            weight = 0.0
            for band, band_weight in self.current_freq_weights.items():
                if band in feats:
                    weight += band_weight * feats[band]
            
            # ì—”íŠ¸ë¡œí”¼(ë³µì¡ë„) ê³ ë ¤
            entropy = feats.get(f'entropy_{self.freq_bands[0]}', 1.0)
            weight *= (1.0 + 0.2 * entropy)  # ë³µì¡í•œ ìƒ˜í”Œì— ì•½ê°„ ë” ë†’ì€ ê°€ì¤‘ì¹˜
            
            weights[sample] = max(0.1, weight)  # ìµœì†Œ ê°€ì¤‘ì¹˜ ë³´ì¥
        
        # ì •ê·œí™”
        total = sum(weights.values())
        if total > 0:
            weights = {k: v/total for k, v in weights.items()}
        
        return weights
    
    def _apply_frequency_enhancement(self, image: np.ndarray) -> np.ndarray:
        """í˜„ì¬ curriculum ë‹¨ê³„ì— ë§ëŠ” ì£¼íŒŒìˆ˜ ê°•í™” ì ìš©"""
        if len(image.shape) == 3:  # RGB
            enhanced_channels = []
            for c in range(image.shape[-1]):
                channel = image[..., c]
                enhanced = self._enhance_single_channel(channel)
                enhanced_channels.append(enhanced)
            result = np.stack(enhanced_channels, axis=-1)
        else:  # Grayscale
            result = self._enhance_single_channel(image)
        
        return np.clip(result, 0, 1)
    
    def _enhance_single_channel(self, channel: np.ndarray) -> np.ndarray:
        """ë‹¨ì¼ ì±„ë„ ì£¼íŒŒìˆ˜ ê°•í™”"""
        # Wavelet Transform
        coeffs = pywt.dwt2(channel, self.wavelet_type)
        LL, (LH, HL, HH) = coeffs
        
        # í˜„ì¬ ë‹¨ê³„ì˜ ê°€ì¤‘ì¹˜ë¡œ ê° ëŒ€ì—­ ì¡°ì •
        LL = LL * self.current_freq_weights['LL']
        LH = LH * self.current_freq_weights['LH']
        HL = HL * self.current_freq_weights['HL']
        HH = HH * self.current_freq_weights['HH']
        
        # Inverse Wavelet Transform
        enhanced = pywt.idwt2((LL, (LH, HL, HH)), self.wavelet_type)
        
        # í¬ê¸° ì¡°ì • (ê²½ê³„ ë¬¸ì œë¡œ ì¸í•œ í¬ê¸° ë³€ê²½ ë³´ì •)
        h, w = channel.shape
        enhanced = enhanced[:h, :w]
        
        return enhanced
    
    def update_curriculum_stage(self, epoch: int) -> bool:
        """Curriculum ë‹¨ê³„ ì—…ë°ì´íŠ¸ (ì£¼íŒŒìˆ˜ ê°€ì¤‘ì¹˜ ì¬ì„¤ì •)"""
        target_stage = "dense"
        if epoch >= self.milestones.get("full", 50):
            target_stage = "full"
        elif epoch >= self.milestones.get("expand", 20):
            target_stage = "expand"
        
        if target_stage != self.stage:
            self.stage = target_stage
            self.current_freq_weights = self._get_freq_weights(self.stage)
            self._load_and_analyze_data()
            logging.info(f"ğŸ”„ [SignalCurriculum] Stage updated: {self.stage.upper()} | "
                        f"Freq weights: {self.current_freq_weights} | "
                        f"Samples: {len(self.samples)}")
            return True
        return False
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        if not self.samples:
            # fallback
            return self._get_fallback_item(idx)
        
        # ê°€ì¤‘ì¹˜ ê¸°ë°˜ ìƒ˜í”Œë§ (ì„ íƒì )
        if hasattr(self, 'sample_weights') and self.sample_weights:
            sample = np.random.choice(
                self.samples, 
                p=[self.sample_weights[s] for s in self.samples]
            )
            npz_path = os.path.join(self.target_path, sample)
        else:
            npz_name = self.samples[idx]
            npz_path = os.path.join(self.target_path, npz_name)
        
        try:
            data = np.load(npz_path, allow_pickle=True)
            imgs = data['imgs'].astype(np.float32) / 255.0
            masks = data['masks'].astype(np.float32)
            
            # ì£¼íŒŒìˆ˜ ê°•í™” ì ìš©
            enhanced_imgs = []
            for t in range(len(imgs)):
                enhanced = self._apply_frequency_enhancement(imgs[t])
                enhanced_imgs.append(enhanced)
            
            enhanced_imgs = np.stack(enhanced_imgs, axis=0)
            
            # ì°¨ì› ì¡°ì •
            if enhanced_imgs.ndim == 4 and enhanced_imgs.shape[-1] == 3:
                enhanced_imgs = enhanced_imgs.transpose(0, 3, 1, 2)
            
            return {
                "video_id": os.path.basename(npz_path).replace(".npz", ""),
                "images": torch.from_numpy(enhanced_imgs).float(),
                "masks": torch.from_numpy(masks).float(),
                "num_frames": len(enhanced_imgs),
                "freq_features": torch.tensor(list(self.freq_features.get(
                    os.path.basename(npz_path), 
                    [1.0]*len(self.freq_bands)
                ))).float(),
                "curriculum_stage": self.stage
            }
        except Exception as e:
            logging.error(f"âŒ Error loading {npz_path}: {e}")
            return self._get_fallback_item(idx)
    
    def _get_fallback_item(self, idx):
        """ì—ëŸ¬ ë°œìƒ ì‹œ ê¸°ë³¸ ì•„ì´í…œ ë°˜í™˜"""
        dummy_img = torch.zeros((1, 3, 256, 256))
        dummy_mask = torch.zeros((1, 256, 256))
        return {
            "video_id": f"dummy_{idx}",
            "images": dummy_img,
            "masks": dummy_mask,
            "num_frames": 1,
            "freq_features": torch.ones(len(self.freq_bands)),
            "curriculum_stage": self.stage
        }


class SignalCurriculumDataset(TorchTrainMixedDataset):
    """
    [SPL Submission Version] 
    Stochastic Temporal Resolution Curriculum
    ê³ ì •ëœ stride ëŒ€ì‹  í™•ë¥ ì  ì§€í„°ë§ì„ í†µí•´ ì‹œê°„ì  ì—ì¼ë¦¬ì–´ì‹±ì„ ì–µì œí•©ë‹ˆë‹¤.
    """
    def __init__(self, *args, max_epochs=100, **kwargs):
        super().__init__(*args, **kwargs)
        self.max_epochs = max_epochs
        # 0.2ê¹Œì§€ Dense, 0.6ê¹Œì§€ Stochastic Expand, ì´í›„ Full
        self.milestones = {"dense": 0.2, "expand": 0.6}

    def get_loader(self, epoch) -> Iterable:
        progress = epoch / self.max_epochs
        
        # í˜ì‹ : strideë¥¼ ê³ ì •ì´ ì•„ë‹Œ 'í™•ë¥ ì  ìƒ˜í”Œë§ ëª¨ë“œ'ë¡œ ì •ì˜
        if progress < self.milestones["dense"]:
            stage, stride, stochastic = "dense", 1, False
        elif progress < self.milestones["expand"]:
            stage, stride, stochastic = "expand", 2, True  # Stochastic ëª¨ë“œ í™œì„±í™”
        else:
            stage, stride, stochastic = "full", 1, False

        dataloaders = []
        for dataset in self.datasets:
            if hasattr(dataset, "stage"): dataset.stage = stage
            if hasattr(dataset, "temporal_stride"): dataset.temporal_stride = stride
            if hasattr(dataset, "use_stochastic"): dataset.use_stochastic = stochastic # ë³€ìˆ˜ ì¶”ê°€
            
            self._set_dataset_epoch(dataset, epoch)
            sampler = DistributedSampler(dataset, shuffle=self.shuffle)
            batch_sampler = BatchSampler(sampler, self.batch_sizes[0], drop_last=self.drop_last)
            dataloaders.append(DataLoader(dataset, batch_sampler=batch_sampler, collate_fn=self.collate_fn))
            
        return MixedDataLoader(dataloaders, self.dataset_prob)
    
    
import numpy as np
import torch
import pywt
import random
from typing import Dict, List, Tuple
from scipy import signal

class NeuroSpectralCurriculumDataset(Dataset):
    """
    Neuro-Inspired Spectral-Temporal Curriculum Learning (NIST-CL)
    
    IEEE SPL í•µì‹¬ ê¸°ì—¬:
    1. ë‡Œì˜ ì‹œê°ì²˜ë¦¬ ê³¼ì • ëª¨ë°© (V1 â†’ V4 â†’ IT)
    2. ìŠ¤í™íŠ¸ëŸ¼-ì‹œê°„ ë„ë©”ì¸ í•˜ì´ë¸Œë¦¬ë“œ ì»¤ë¦¬í˜ëŸ¼
    3. Adaptive Stochastic Resonance ê¸°ë²•
    4. ë©”ëª¨ë¦¬ ê¸°ë°˜ ì£¼íŒŒìˆ˜ ê°€ì¤‘ì¹˜ í•™ìŠµ
    """
    
    def __init__(
        self,
        folder: str,
        milestones: Dict[str, int],
        wavelet_type: str = 'db4',
        neuro_layers: List[str] = ['V1', 'V2', 'V4', 'IT'],  # ë‡Œ ì˜ì—­ ì‹œë®¬ë ˆì´ì…˜
        use_binaural: bool = True,  # ì˜ì‚¬ ìŠ¤í…Œë ˆì˜¤ ì²­ê° íš¨ê³¼
        **kwargs
    ):
        """
        Args:
            folder: ë°ì´í„° í´ë”
            milestones: ì»¤ë¦¬í˜ëŸ¼ ë§ˆì¼ìŠ¤í†¤
            neuro_layers: ëª¨ë°©í•  ë‡Œ ì‹œê°í”¼ì§ˆ ì˜ì—­
            use_binaural: ì˜ì‚¬ ìŠ¤í…Œë ˆì˜¤ íš¨ê³¼ (ì£¼íŒŒìˆ˜ ë¶„ë¦¬)
        """
        self.base_folder = folder
        self.milestones = milestones
        self.wavelet_type = wavelet_type
        self.neuro_layers = neuro_layers
        self.use_binaural = use_binaural
        
        # ì‹ ê²½í•™ì  ìƒíƒœ
        self.neuro_stage = "V1_dense"  # ì´ˆê¸°: V1 í”¼ì§ˆ (ë‹¨ìˆœí•œ íŠ¹ì§•)
        self.activation_history = []  # í•™ìŠµ í™œì„±í™” ê¸°ë¡
        self.memory_weights = {}  # ìƒ˜í”Œë³„ ì£¼íŒŒìˆ˜ ë©”ëª¨ë¦¬
        
        # í˜ì‹  1: ì£¼íŒŒìˆ˜-ì‹œê°„ ê²°í•© ê°€ì¤‘ì¹˜
        self.spectro_temporal_weights = self._init_neuro_weights()
        
        # í˜ì‹  2: Adaptive Stochastic Resonance íŒŒë¼ë¯¸í„°
        self.stochastic_resonance = {
            'noise_level': 0.1,  # ì´ˆê¸° ë…¸ì´ì¦ˆ
            'resonance_freq': [],  # ê³µì§„ ì£¼íŒŒìˆ˜
            'adaptation_rate': 0.01
        }
        
        self.samples = []
        self._load_and_analyze_data()
        
        logging.info(f"ğŸ§  [NIST-CL] Neuro Stage: {self.neuro_stage} | "
                    f"Samples: {len(self.samples)} | "
                    f"SR Noise: {self.stochastic_resonance['noise_level']:.3f}")
    
    def _init_neuro_weights(self) -> Dict:
        """ë‡Œ ì˜ì—­ë³„ ìŠ¤í™íŠ¸ëŸ¼-ì‹œê°„ ê°€ì¤‘ì¹˜"""
        return {
            'V1_dense': {'low_freq': 0.9, 'mid_freq': 0.2, 'high_freq': 0.05, 'temporal': 0.1},
            'V2_expand': {'low_freq': 0.7, 'mid_freq': 0.6, 'high_freq': 0.3, 'temporal': 0.3},
            'V4_complex': {'low_freq': 0.5, 'mid_freq': 0.8, 'high_freq': 0.6, 'temporal': 0.6},
            'IT_full': {'low_freq': 0.3, 'mid_freq': 0.9, 'high_freq': 0.9, 'temporal': 0.9}
        }
    
    def _analyze_spectro_temporal_features(self, npz_path: str) -> Dict:
        """ìŠ¤í™íŠ¸ëŸ¼-ì‹œê°„ ê²°í•© íŠ¹ì§• ë¶„ì„"""
        try:
            data = np.load(npz_path, allow_pickle=True)
            imgs = data['imgs']
            
            # ì‹œê°„ ì¶•ì„ ë”°ë¼ STFT (Short-Time Fourier Transform)
            if imgs.ndim == 4:  # (T, H, W, 3)
                video_series = np.mean(imgs, axis=(1, 2, 3))  # ì‹œê°„ë³„ í‰ê·  ë°ê¸°
            else:  # (T, H, W)
                video_series = np.mean(imgs, axis=(1, 2))
            
            # STFT ë¶„ì„
            f, t, Zxx = signal.stft(video_series, fs=30, nperseg=min(16, len(video_series)))
            
            # ì£¼ìš” ì£¼íŒŒìˆ˜ ëŒ€ì—­ ì—ë„ˆì§€
            low_freq_idx = f < 5  # ì €ì£¼íŒŒ (<5Hz)
            mid_freq_idx = (f >= 5) & (f < 15)  # ì¤‘ì£¼íŒŒ
            high_freq_idx = f >= 15  # ê³ ì£¼íŒŒ
            
            features = {
                'low_freq_energy': np.mean(np.abs(Zxx[low_freq_idx, :])),
                'mid_freq_energy': np.mean(np.abs(Zxx[mid_freq_idx, :])),
                'high_freq_energy': np.mean(np.abs(Zxx[high_freq_idx, :])),
                'temporal_coherence': self._compute_temporal_coherence(Zxx),
                'spectral_entropy': self._compute_spectral_entropy(Zxx),
                'harmonic_ratio': self._compute_harmonic_ratio(Zxx, f)
            }
            
            # í˜ì‹ : ì˜ì‚¬ ìŠ¤í…Œë ˆì˜¤ íš¨ê³¼ ìƒì„±
            if self.use_binaural:
                left_ch, right_ch = self._create_binaural_signature(Zxx, f)
                features['binaural_asymmetry'] = np.abs(left_ch - right_ch).mean()
            
            return features
            
        except Exception as e:
            logging.warning(f"Spectro-temporal analysis failed: {e}")
            return {'low_freq_energy': 1.0, 'mid_freq_energy': 0.5, 'high_freq_energy': 0.1,
                   'temporal_coherence': 0.5, 'spectral_entropy': 1.0, 'harmonic_ratio': 0.5}
    
    def _compute_temporal_coherence(self, Zxx: np.ndarray) -> float:
        """ì‹œê°„ì  ì¼ê´€ì„± ê³„ì‚° (phase coherence)"""
        phases = np.angle(Zxx)
        phase_diff = np.diff(phases, axis=1)
        coherence = np.mean(np.cos(phase_diff))  # ì½”ì‚¬ì¸ ìœ ì‚¬ë„
        return float(np.clip(coherence, 0, 1))
    
    def _compute_spectral_entropy(self, Zxx: np.ndarray) -> float:
        """ìŠ¤í™íŠ¸ëŸ¼ ì—”íŠ¸ë¡œí”¼"""
        power = np.abs(Zxx) ** 2
        power_sum = np.sum(power, axis=0)
        prob = power / (power_sum + 1e-10)
        entropy = -np.sum(prob * np.log2(prob + 1e-10)) / np.log2(power.shape[0])
        return float(entropy)
    
    def _compute_harmonic_ratio(self, Zxx: np.ndarray, f: np.ndarray) -> float:
        """ì¡°í™” ë¹„ìœ¨ ê³„ì‚° (ì •ìƒì ì¸ ë¹„ë””ì˜¤ vs ë³‘ë¦¬ì  ë¹„ë””ì˜¤)"""
        # ê¸°ë³¸ ì£¼íŒŒìˆ˜ ì¶”ì •
        power = np.mean(np.abs(Zxx), axis=1)
        fundamental_idx = np.argmax(power)
        fundamental_freq = f[fundamental_idx]
        
        if fundamental_freq < 1e-6:
            return 0.0
            
        # ê³ ì¡°íŒŒ ìœ„ì¹˜ í™•ì¸
        harmonic_indices = []
        for n in range(2, 6):  # 2ì°¨~5ì°¨ ê³ ì¡°íŒŒ
            target_freq = fundamental_freq * n
            idx = np.argmin(np.abs(f - target_freq))
            harmonic_indices.append(idx)
        
        # ê³ ì¡°íŒŒ ê°•ë„ í•©
        harmonic_power = sum(power[i] for i in harmonic_indices if i < len(power))
        total_power = np.sum(power)
        
        return float(harmonic_power / (total_power + 1e-10))
    
    def _create_binaural_signature(self, Zxx: np.ndarray, f: np.ndarray) -> Tuple[float, float]:
        """ì˜ì‚¬ ìŠ¤í…Œë ˆì˜¤ ì²­ê° íš¨ê³¼ ìƒì„±"""
        # ì €ì£¼íŒŒëŠ” ì™¼ìª½, ê³ ì£¼íŒŒëŠ” ì˜¤ë¥¸ìª½ìœ¼ë¡œ ë¶„ë¦¬
        mid_freq = np.median(f)
        left_ch = np.mean(np.abs(Zxx[f <= mid_freq, :]))
        right_ch = np.mean(np.abs(Zxx[f > mid_freq, :]))
        return left_ch, right_ch
    
    def _apply_neuro_inspired_processing(self, image: np.ndarray, sample_id: str) -> np.ndarray:
        """ì‹ ê²½í•™ì  ì˜ìƒ ì²˜ë¦¬ (V1 â†’ IT ê³¼ì • ëª¨ë°©)"""
        weights = self.spectro_temporal_weights[self.neuro_stage]
        
        # Wavelet ë¶„í•´
        coeffs = pywt.wavedec2(image, self.wavelet_type, level=3)
        
        # ê° ì£¼íŒŒìˆ˜ ëŒ€ì—­ì— ê°€ì¤‘ì¹˜ ì ìš©
        processed_coeffs = []
        for i, coeff in enumerate(coeffs):
            if i == 0:  # ê°€ì¥ ì €ì£¼íŒŒ (LLL)
                weight = weights['low_freq']
            elif i == 1:  # ì¤‘ê°„ ì£¼íŒŒìˆ˜
                weight = weights['mid_freq']
            else:  # ê³ ì£¼íŒŒ
                weight = weights['high_freq']
            
            # í˜ì‹ : Adaptive Stochastic Resonance ì ìš©
            if self.stochastic_resonance['noise_level'] > 0:
                noise = np.random.randn(*coeff.shape) * self.stochastic_resonance['noise_level']
                # ê³µì§„ ì£¼íŒŒìˆ˜ ê°•ì¡°
                if hasattr(self, 'resonance_freq') and i in self.stochastic_resonance['resonance_freq']:
                    coeff = coeff * 1.5
                coeff = coeff + noise * weight
            
            processed_coeffs.append(coeff * weight)
        
        # Wavelet ì¬êµ¬ì„±
        processed = pywt.waverec2(processed_coeffs, self.wavelet_type)
        
        # ì‹œê°„ì  ì²˜ë¦¬ (ê°„ë‹¨í•œ ëª¨ì…˜ ë¸”ëŸ¬ ì‹œë®¬ë ˆì´ì…˜)
        if weights['temporal'] > 0.3:
            # ê°€ìƒì˜ ì‹œê°„ì  í†µí•©
            kernel_size = int(3 * weights['temporal'])
            if kernel_size > 1:
                kernel = np.ones((kernel_size, kernel_size)) / (kernel_size ** 2)
                from scipy import ndimage
                processed = ndimage.convolve(processed, kernel, mode='reflect')
        
        # ë©”ëª¨ë¦¬ ê¸°ë°˜ ë³´ì •
        if sample_id in self.memory_weights:
            mem_weight = self.memory_weights[sample_id].get('enhancement', 1.0)
            processed = processed * mem_weight
        
        return np.clip(processed, 0, 1)
    
    def _update_stochastic_resonance(self, epoch: int, loss_history: List[float] = None):
        """Adaptive Stochastic Resonance ì—…ë°ì´íŠ¸"""
        # ì ì§„ì  ë…¸ì´ì¦ˆ ê°ì†Œ
        decay = np.exp(-epoch / 50)
        self.stochastic_resonance['noise_level'] = 0.1 * decay
        
        # ì†ì‹¤ ê¸°ë°˜ ì ì‘
        if loss_history and len(loss_history) > 10:
            recent_loss = np.mean(loss_history[-5:])
            prev_loss = np.mean(loss_history[-10:-5])
            
            if recent_loss < prev_loss * 0.95:  # 5% í–¥ìƒ
                # ë…¸ì´ì¦ˆ ë” ì¤„ì´ê¸°
                self.stochastic_resonance['noise_level'] *= 0.9
            elif recent_loss > prev_loss * 1.05:  # 5% ì•…í™”
                # ì•½ê°„ì˜ ë…¸ì´ì¦ˆ ì¶”ê°€ (íƒìƒ‰ ì´‰ì§„)
                self.stochastic_resonance['noise_level'] = min(0.05, 
                    self.stochastic_resonance['noise_level'] * 1.1)
        
        # ê³µì§„ ì£¼íŒŒìˆ˜ í•™ìŠµ
        if epoch % 10 == 0:
            self._learn_resonance_frequencies()
    
    def _learn_resonance_frequencies(self):
        """í•™ìŠµ ë°ì´í„°ì—ì„œ ê³µì§„ ì£¼íŒŒìˆ˜ ë°œê²¬"""
        if not hasattr(self, 'freq_features') or len(self.freq_features) < 5:
            return
        
        # ëª¨ë“  ìƒ˜í”Œì˜ ì£¼íŒŒìˆ˜ íŠ¹ì§• í‰ê· 
        avg_features = {}
        for band in ['low_freq_energy', 'mid_freq_energy', 'high_freq_energy']:
            values = [feat.get(band, 0) for feat in self.freq_features.values()]
            avg_features[band] = np.mean(values)
        
        # ê°€ì¥ ê°•í•œ ì£¼íŒŒìˆ˜ ëŒ€ì—­ ì°¾ê¸°
        max_band = max(avg_features, key=avg_features.get)
        
        # ê³µì§„ ì£¼íŒŒìˆ˜ ë§µí•‘
        band_to_level = {
            'low_freq_energy': 0,  # ê°€ì¥ ì €ì£¼íŒŒ
            'mid_freq_energy': 1,  # ì¤‘ê°„
            'high_freq_energy': 2   # ê³ ì£¼íŒŒ
        }
        
        if max_band in band_to_level:
            self.stochastic_resonance['resonance_freq'] = [band_to_level[max_band]]
            logging.info(f"ğŸ§  Learned resonance frequency: {max_band}")
    
    def _update_memory_weights(self, sample_id: str, loss: float = None):
        """ë©”ëª¨ë¦¬ ê¸°ë°˜ ê°€ì¤‘ì¹˜ í•™ìŠµ"""
        if sample_id not in self.memory_weights:
            self.memory_weights[sample_id] = {
                'enhancement': 1.0,
                'difficulty': 0.5,
                'visit_count': 0
            }
        
        mem = self.memory_weights[sample_id]
        mem['visit_count'] += 1
        
        # ì†ì‹¤ ê¸°ë°˜ ì ì‘
        if loss is not None:
            if loss < 0.1:  # ì˜ í•™ìŠµë¨
                mem['difficulty'] *= 0.95
            else:  # ì–´ë ¤ì›€
                mem['difficulty'] = min(1.0, mem['difficulty'] * 1.05)
            
            # ì–´ë ¤ìš´ ìƒ˜í”Œì€ ë” ê°•í•˜ê²Œ ì²˜ë¦¬
            mem['enhancement'] = 1.0 + 0.5 * mem['difficulty']
    
    def update_neuro_stage(self, epoch: int, loss_history: List[float] = None) -> bool:
        """ì‹ ê²½í•™ì  ì»¤ë¦¬í˜ëŸ¼ ë‹¨ê³„ ì—…ë°ì´íŠ¸"""
        progress = epoch / self.milestones.get("full", 50)
        
        old_stage = self.neuro_stage
        
        if progress < 0.2:
            self.neuro_stage = "V1_dense"
        elif progress < 0.6:
            self.neuro_stage = "V2_expand"
        elif progress < 0.9:
            self.neuro_stage = "V4_complex"
        else:
            self.neuro_stage = "IT_full"
        
        # Stochastic Resonance ì—…ë°ì´íŠ¸
        self._update_stochastic_resonance(epoch, loss_history)
        
        if old_stage != self.neuro_stage:
            logging.info(f"ğŸ§  [NIST-CL] Neuro stage updated: {old_stage} â†’ {self.neuro_stage}")
            return True
        return False
    
    def _load_and_analyze_data(self):
        """ë°ì´í„° ë¡œë“œ ë° íŠ¹ì§• ë¶„ì„"""
        self.target_path = os.path.join(self.base_folder, self.neuro_stage.split('_')[0], "uterine_niche")
        if not os.path.exists(self.target_path):
            self.target_path = os.path.join(self.base_folder, self.neuro_stage.split('_')[0])
        
        if os.path.exists(self.target_path):
            all_samples = sorted([f for f in os.listdir(self.target_path) if f.endswith('.npz')])
            
            # ìŠ¤í™íŠ¸ëŸ¼-ì‹œê°„ íŠ¹ì§• ë¶„ì„
            self.freq_features = {}
            valid_samples = []
            
            for sample in all_samples:
                npz_path = os.path.join(self.target_path, sample)
                features = self._analyze_spectro_temporal_features(npz_path)
                self.freq_features[sample] = features
                
                # ë‹¨ê³„ë³„ í•„í„°ë§
                if self._neuro_sample_filter(features):
                    valid_samples.append(sample)
            
            self.samples = valid_samples
        else:
            self.samples = []
    
    def _neuro_sample_filter(self, features: Dict) -> bool:
        """ì‹ ê²½í•™ì  ìƒ˜í”Œ í•„í„°ë§"""
        if "V1" in self.neuro_stage:
            # ì €ì£¼íŒŒ ê°•ì¡°, ë‹¨ìˆœí•œ ìƒ˜í”Œ
            return features['low_freq_energy'] > 0.7 and features['spectral_entropy'] < 0.6
        elif "V2" in self.neuro_stage:
            # ì¤‘ê°„ ë³µì¡ë„
            return features['mid_freq_energy'] > 0.4 and features['temporal_coherence'] > 0.3
        elif "V4" in self.neuro_stage:
            # ê³ ì£¼íŒŒ í¬í•¨
            return features['high_freq_energy'] > 0.2 and features['harmonic_ratio'] > 0.3
        else:  # IT
            # ëª¨ë“  ìƒ˜í”Œ
            return True
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        if not self.samples:
            return self._get_fallback_item(idx)
        
        # ì–´ë ¤ì›€ ê¸°ë°˜ ìƒ˜í”Œë§
        if hasattr(self, 'memory_weights') and self.memory_weights:
            difficulties = [self.memory_weights.get(s, {}).get('difficulty', 0.5) 
                          for s in self.samples]
            # ì–´ë ¤ìš´ ìƒ˜í”Œì„ ë” ìì£¼ ìƒ˜í”Œë§ (í•™ìŠµ ì´‰ì§„)
            probs = np.array(difficulties) / np.sum(difficulties)
            sample_idx = np.random.choice(len(self.samples), p=probs)
            sample = self.samples[sample_idx]
        else:
            sample = self.samples[idx]
        
        npz_path = os.path.join(self.target_path, sample)
        
        try:
            data = np.load(npz_path, allow_pickle=True)
            imgs = data['imgs'].astype(np.float32)
            
            if imgs.max() > 1.0:
                imgs = imgs / 255.0
            
            masks = data['masks'].astype(np.float32)
            
            # ì‹ ê²½í•™ì  ì²˜ë¦¬
            processed_imgs = []
            for t in range(len(imgs)):
                if imgs.ndim == 4:
                    img = imgs[t]
                else:
                    img = imgs[t]
                
                # RGB ì±„ë„ë³„ ì²˜ë¦¬
                if img.ndim == 3 and img.shape[-1] == 3:
                    channels = []
                    for c in range(3):
                        processed = self._apply_neuro_inspired_processing(img[..., c], sample)
                        channels.append(processed)
                    processed_img = np.stack(channels, axis=-1)
                else:
                    processed_img = self._apply_neuro_inspired_processing(img, sample)
                
                processed_imgs.append(processed_img)
            
            processed_imgs = np.stack(processed_imgs, axis=0).astype(np.float32)
            
            # ì°¨ì› ì¡°ì •
            if processed_imgs.ndim == 4 and processed_imgs.shape[-1] == 3:
                processed_imgs = processed_imgs.transpose(0, 3, 1, 2)
            
            # íŠ¹ì§• ë²¡í„° ì¤€ë¹„
            feats = self.freq_features.get(sample, {})
            feature_vector = [
                feats.get('low_freq_energy', 0.5),
                feats.get('mid_freq_energy', 0.5),
                feats.get('high_freq_energy', 0.2),
                feats.get('temporal_coherence', 0.5),
                feats.get('spectral_entropy', 0.5)
            ]
            
            item = {
                "video_id": sample.replace(".npz", ""),
                "images": torch.from_numpy(processed_imgs).float(),
                "masks": torch.from_numpy(masks).float(),
                "num_frames": len(processed_imgs),
                "neuro_features": torch.tensor(feature_vector).float(),
                "neuro_stage": self.neuro_stage,
                "stochastic_noise": self.stochastic_resonance['noise_level']
            }
            
            # ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ë¥¼ ìœ„í•œ ìƒ˜í”Œ ID ì €ì¥
            item['sample_id'] = sample
            
            return item
            
        except Exception as e:
            logging.error(f"âŒ [NIST-CL] Error loading {npz_path}: {e}")
            return self._get_fallback_item(idx)
    
    def _get_fallback_item(self, idx):
        dummy_img = torch.zeros((1, 3, 256, 256))
        dummy_mask = torch.zeros((1, 256, 256))
        return {
            "video_id": f"dummy_{idx}",
            "images": dummy_img,
            "masks": dummy_mask,
            "num_frames": 1,
            "neuro_features": torch.ones(5) * 0.5,
            "neuro_stage": self.neuro_stage,
            "stochastic_noise": 0.0,
            "sample_id": f"dummy_{idx}"
        }


class AESCurriculumDataset(Dataset):
    """
    Adaptive Entropy Sampling Curriculum Learning
    
    IEEE SPL ì¥ì :
    1. ì •ë³´ ì´ë¡  ê¸°ë°˜ (Shannon entropy)
    2. ê³„ì‚° íš¨ìœ¨ì 
    3. í•´ì„ ê°€ëŠ¥ì„± ë†’ìŒ
    4. ì˜ë£Œ ì˜ìƒì˜ ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”
    """
    
    def __init__(self, folder, milestones, entropy_threshold=0.7, **kwargs):
        self.base_folder = folder
        self.milestones = milestones
        self.entropy_threshold = entropy_threshold
        self.adaptive_factor = 1.0
        
        self.stage = "dense"
        self.samples = []
        self.sample_entropies = {}  # ìƒ˜í”Œë³„ ì—”íŠ¸ë¡œí”¼ ì €ì¥
        
        self._load_and_compute_entropy()
    
    def _compute_image_entropy(self, image):
        """ì´ë¯¸ì§€ì˜ ì •ë³´ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""
        if len(image.shape) == 3:
            image = np.mean(image, axis=2)  # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
        
        # íˆìŠ¤í† ê·¸ë¨ ê¸°ë°˜ ì—”íŠ¸ë¡œí”¼
        hist, _ = np.histogram(image.flatten(), bins=32, range=(0, 1))
        prob = hist / hist.sum()
        entropy = -np.sum(prob * np.log2(prob + 1e-10))
        
        # ì •ê·œí™” (0-1)
        return entropy / 5.0  # max entropy for 32 bins is log2(32) = 5
    
    def _compute_mask_complexity(self, mask):
        """ë§ˆìŠ¤í¬ì˜ í˜•íƒœí•™ì  ë³µì¡ë„ ê³„ì‚°"""
        if np.sum(mask) == 0:
            return 0.0
        
        from skimage.measure import perimeter, euler_number
        from scipy import ndimage
        
        # ê²½ê³„ ê¸¸ì´ / ë©´ì  ë¹„ìœ¨
        area = np.sum(mask)
        perim = perimeter(mask)
        boundary_complexity = perim / (area + 1e-10)
        
        # ìœ„ìƒí•™ì  ë³µì¡ë„ (ì˜¤ì¼ëŸ¬ ìˆ˜)
        labeled, num_features = ndimage.label(mask)
        euler = euler_number(mask)
        
        # ì •ê·œí™”ëœ ë³µì¡ë„ ì ìˆ˜
        complexity = boundary_complexity * 0.1 + abs(euler) * 0.1
        return min(complexity, 1.0)
    
    def _load_and_compute_entropy(self):
        """ë°ì´í„° ë¡œë“œ ë° ì—”íŠ¸ë¡œí”¼ ê³„ì‚°"""
        self.target_path = os.path.join(self.base_folder, self.stage, "uterine_niche")
        if not os.path.exists(self.target_path):
            self.target_path = os.path.join(self.base_folder, self.stage)
        
        if not os.path.exists(self.target_path):
            self.samples = []
            return
        
        all_samples = sorted([f for f in os.listdir(self.target_path) if f.endswith('.npz')])
        
        # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ìƒ˜í”Œ í•„í„°ë§
        self.samples = []
        self.sample_entropies.clear()
        
        for sample in all_samples:
            try:
                data = np.load(os.path.join(self.target_path, sample), allow_pickle=True)
                imgs = data['imgs']
                masks = data['masks']
                
                # ì²« í”„ë ˆì„ì˜ ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
                if len(imgs) > 0:
                    img_entropy = self._compute_image_entropy(imgs[0])
                    mask_complexity = self._compute_mask_complexity(masks[0])
                    
                    # ì¢…í•© ì—”íŠ¸ë¡œí”¼ ì ìˆ˜
                    total_entropy = (img_entropy + mask_complexity) / 2
                    self.sample_entropies[sample] = total_entropy
                    
                    # ë‹¨ê³„ë³„ í•„í„°ë§
                    if self._entropy_filter(total_entropy):
                        self.samples.append(sample)
                        
            except Exception as e:
                logging.warning(f"Entropy computation failed for {sample}: {e}")
    
    def _entropy_filter(self, entropy):
        """ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ìƒ˜í”Œ í•„í„°ë§"""
        if self.stage == "dense":
            return entropy < 0.3 * self.adaptive_factor
        elif self.stage == "expand":
            return entropy < 0.6 * self.adaptive_factor
        else:  # full
            return True
    
    def update_curriculum_stage(self, epoch, training_loss=None):
        """ì»¤ë¦¬í˜ëŸ¼ ë‹¨ê³„ ë° ì ì‘í˜• íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸"""
        target_stage = "dense"
        if epoch >= self.milestones.get("full", 50):
            target_stage = "full"
        elif epoch >= self.milestones.get("expand", 20):
            target_stage = "expand"
        
        # ì†ì‹¤ ê¸°ë°˜ adaptive factor ì¡°ì •
        if training_loss is not None:
            if training_loss < 0.1:
                self.adaptive_factor = min(2.0, self.adaptive_factor * 1.05)
            else:
                self.adaptive_factor = max(0.5, self.adaptive_factor * 0.95)
        
        if target_stage != self.stage:
            self.stage = target_stage
            self._load_and_compute_entropy()
            logging.info(f"ğŸ“Š [AES-CL] Stage: {self.stage} | "
                        f"Adaptive factor: {self.adaptive_factor:.2f} | "
                        f"Samples: {len(self.samples)}")
            return True
        return False
    
    def __getitem__(self, idx):
        # ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ì¤‘ìš”ë„ ìƒ˜í”Œë§
        if self.sample_entropies and len(self.samples) > 0:
            # ë‚®ì€ ì—”íŠ¸ë¡œí”¼ ìƒ˜í”Œì— ë†’ì€ í™•ë¥  (ì´ˆê¸°), ë†’ì€ ì—”íŠ¸ë¡œí”¼ì— ë†’ì€ í™•ë¥  (í›„ê¸°)
            if self.stage == "dense":
                # ë‚®ì€ ì—”íŠ¸ë¡œí”¼ ì„ í˜¸
                probs = [1.0/(self.sample_entropies[s] + 0.1) for s in self.samples]
            elif self.stage == "expand":
                # ê· ë“±
                probs = [1.0] * len(self.samples)
            else:
                # ë†’ì€ ì—”íŠ¸ë¡œí”¼ ì„ í˜¸
                probs = [self.sample_entropies[s] + 0.1 for s in self.samples]
            
            probs = np.array(probs) / sum(probs)
            sample_idx = np.random.choice(len(self.samples), p=probs)
            npz_name = self.samples[sample_idx]
        else:
            npz_name = self.samples[idx % len(self.samples)] if self.samples else None
        
        # ë‚˜ë¨¸ì§€ ë°ì´í„° ë¡œë”©ì€ ê¸°ì¡´ê³¼ ë™ì¼
        # ... (ìƒëµ)

import numpy as np
import torch
from scipy import ndimage
from typing import Dict, List
import os
import logging
import numpy as np
import torch
from torch.utils.data import Dataset

# class QuantumResonanceCurriculumDataset(Dataset):
#     """
#     Quantum-Inspired Resonance Curriculum Learning (QIR-CL)
#     ê¸°ì¡´ MedSAM2CurriculumDatasetê³¼ ì™„ì „ í˜¸í™˜ (repeat_factors í¬í•¨)
#     """
    
#     def __init__(self, folder, milestones, **kwargs):
#         """
#         ê¸°ì¡´ MedSAM2CurriculumDatasetê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
#         """
#         self.base_folder = folder
#         self.milestones = milestones
        
#         # ê¸°ì¡´ê³¼ ë™ì¼í•œ ë³€ìˆ˜ë“¤
#         self.stage = "dense"
#         self.samples = []
#         self.repeat_factors = None  # RepeatFactorWrapperë¥¼ ìœ„í•´ í•„ìš”
        
#         # ì–‘ì ê°œë… (ë‚´ë¶€ì ìœ¼ë¡œë§Œ ì‚¬ìš©)
#         self._quantum_state = "ground"
#         self._coherence = 0.1
#         self._resonance_freqs = [0.25, 0.5, 0.75, 1.0]
        
#         self._load_stage_data("dense")
        
#         # repeat_factors ì´ˆê¸°í™” (ëª¨ë“  ìƒ˜í”Œ ë™ì¼ ê°€ì¤‘ì¹˜)
#         if self.samples:
#             self.repeat_factors = torch.ones(len(self.samples))
        
#         logging.info(f"âš›ï¸ [QIR-CL] Initialized | Stage: {self.stage.upper()} | Samples: {len(self.samples)}")
    
#     def _load_stage_data(self, stage):
#         """ê¸°ì¡´ê³¼ ë™ì¼í•œ ë°ì´í„° ë¡œë“œ ë¡œì§"""
#         self.stage = stage
        
#         # ê²½ë¡œ: base_folder / stage / uterine_niche
#         self.target_path = os.path.join(self.base_folder, self.stage, "uterine_niche")
        
#         if not os.path.exists(self.target_path):
#             # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒìœ„ ë‹¨ê³„ í´ë” ì°¸ì¡°
#             self.target_path = os.path.join(self.base_folder, self.stage)
        
#         if os.path.exists(self.target_path):
#             # ëª¨ë“  NPZ íŒŒì¼ ìˆ˜ì§‘
#             all_samples = sorted([f for f in os.listdir(self.target_path) if f.endswith('.npz')])
            
#             # ë””ë²„ê·¸: í´ë” ë‚´ìš© í™•ì¸
#             logging.info(f"ğŸ“ Path: {self.target_path}")
#             logging.info(f"ğŸ“ Files in directory: {os.listdir(self.target_path)[:5] if os.path.exists(self.target_path) else 'Directory not found'}")
            
#             if not all_samples:
#                 logging.warning(f"No .npz files found in {self.target_path}")
#                 self.samples = []
#             else:
#                 # ì–‘ì ìƒíƒœì— ë”°ë¥¸ ìƒ˜í”Œ í•„í„°ë§
#                 self.samples = self._quantum_filter_samples(all_samples)
                
#                 # ê³µëª… ì£¼íŒŒìˆ˜ ì—…ë°ì´íŠ¸
#                 self._update_resonance_frequencies()
#         else:
#             logging.warning(f"Target path does not exist: {self.target_path}")
#             self.samples = []
    
#     def _quantum_filter_samples(self, all_samples):
#         """ì–‘ì ìƒíƒœì— ë”°ë¥¸ ìƒ˜í”Œ í•„í„°ë§"""
#         if self._quantum_state == "ground" and len(all_samples) > 5:
#             # ì´ˆê¸°: ì‘ì€ íŒŒì¼ë§Œ ì„ íƒ (ë‹¨ìˆœí•œ ìƒ˜í”Œ)
#             filtered = []
#             for sample in all_samples:
#                 try:
#                     path = os.path.join(self.target_path, sample)
#                     size_mb = os.path.getsize(path) / (1024 * 1024)  # MB ë‹¨ìœ„
#                     if size_mb < 5.0:  # 5MB ë¯¸ë§Œì˜ ì‘ì€ íŒŒì¼
#                         filtered.append(sample)
#                 except:
#                     filtered.append(sample)
            
#             # ìµœì†Œ 3ê°œëŠ” ë³´ì¥
#             if len(filtered) < 3:
#                 filtered = all_samples[:min(10, len(all_samples))]
            
#             return filtered
        
#         elif self._quantum_state == "excited" and len(all_samples) > 10:
#             # ì¤‘ê°„: ì¤‘ê°„ í¬ê¸° ìƒ˜í”Œ
#             return all_samples[:len(all_samples)//2]
        
#         else:
#             # ëª¨ë“  ìƒ˜í”Œ
#             return all_samples
    
#     def _update_resonance_frequencies(self):
#         """ê³µëª… ì£¼íŒŒìˆ˜ ì—…ë°ì´íŠ¸"""
#         if not self.samples:
#             self._resonance_freqs = [0.25, 0.5, 0.75, 1.0]
#             return
        
#         try:
#             # ë¬´ì‘ìœ„ ìƒ˜í”Œë¡œ ì£¼íŒŒìˆ˜ ë¶„ì„
#             sample_idx = np.random.randint(0, len(self.samples))
#             sample_path = os.path.join(self.target_path, self.samples[sample_idx])
            
#             data = np.load(sample_path, allow_pickle=True)
#             img = data['imgs'][0]
            
#             # ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ë³€í™˜
#             if img.ndim == 3 and img.shape[-1] == 3:
#                 img = np.mean(img, axis=2)
            
#             # ê°„ë‹¨í•œ FFT ë¶„ì„
#             fft = np.fft.fft2(img)
#             magnitude = np.abs(np.fft.fftshift(fft))
            
#             h, w = magnitude.shape
#             energies = [
#                 np.mean(magnitude[:h//2, :w//2]),  # ì €ì£¼íŒŒ
#                 np.mean(magnitude[:h//2, w//2:]),  # ì¤‘ì €ì£¼íŒŒ
#                 np.mean(magnitude[h//2:, :w//2]),  # ì¤‘ê³ ì£¼íŒŒ
#                 np.mean(magnitude[h//2:, w//2:])   # ê³ ì£¼íŒŒ
#             ]
            
#             max_energy = max(energies) if max(energies) > 0 else 1.0
#             self._resonance_freqs = [e/max_energy for e in energies]
            
#         except Exception as e:
#             logging.warning(f"Resonance frequency update failed: {e}")
#             self._resonance_freqs = [0.25, 0.5, 0.75, 1.0]
    
#     def _apply_quantum_enhancement(self, image):
#         """ì–‘ì ê³µëª… ê¸°ë°˜ ì´ë¯¸ì§€ í–¥ìƒ"""
#         if image.ndim == 3 and image.shape[-1] == 3:
#             # RGB: ì±„ë„ë³„ ì²˜ë¦¬
#             enhanced_channels = []
#             for c in range(3):
#                 channel = image[:, :, c]
#                 enhanced = self._enhance_channel(channel)
#                 enhanced_channels.append(enhanced)
#             result = np.stack(enhanced_channels, axis=-1)
#         else:
#             result = self._enhance_channel(image)
        
#         return np.clip(result, 0, 1)
    
#     def _enhance_channel(self, channel):
#         """ë‹¨ì¼ ì±„ë„ ì–‘ì í–¥ìƒ"""
#         # FFT ë³€í™˜
#         fft = np.fft.fft2(channel)
#         fshift = np.fft.fftshift(fft)
#         magnitude = np.abs(fshift)
#         phase = np.angle(fshift)
        
#         rows, cols = channel.shape
#         crow, ccol = rows // 2, cols // 2
        
#         # ì–‘ì ìƒíƒœì— ë”°ë¥¸ ì¦í­
#         if self._quantum_state == "ground":
#             # ì €ì£¼íŒŒ ê°•ì¡°
#             radius = 30
#             mask = np.zeros((rows, cols))
#             y, x = np.ogrid[:rows, :cols]
#             mask_area = (x - ccol)**2 + (y - crow)**2 <= radius**2
#             magnitude[mask_area] *= 1.3
            
#         elif self._quantum_state == "excited":
#             # ì¤‘ì£¼íŒŒ ê°•ì¡°
#             inner_radius = 20
#             outer_radius = 60
#             y, x = np.ogrid[:rows, :cols]
#             dist_from_center = np.sqrt((x - ccol)**2 + (y - crow)**2)
#             mask = (dist_from_center >= inner_radius) & (dist_from_center <= outer_radius)
#             magnitude[mask] *= 1.5
            
#         elif self._quantum_state == "coherent":
#             # ê³ ì£¼íŒŒ ê°•ì¡°
#             radius = 30
#             y, x = np.ogrid[:rows, :cols]
#             mask_area = (x - ccol)**2 + (y - crow)**2 <= radius**2
#             magnitude[~mask_area] *= 1.4
            
#         else:  # resonant
#             # ëª¨ë“  ì£¼íŒŒìˆ˜ ê· í˜•
#             magnitude *= 1.2
        
#         # ìœ„ìƒ ì¡°ì • (ê²°ë§ìŒë„ì— ë”°ë¼)
#         phase_shift = self._coherence * 0.5
#         phase = phase + phase_shift
        
#         # ì—­ë³€í™˜
#         enhanced = magnitude * np.exp(1j * phase)
#         f_ishift = np.fft.ifftshift(enhanced)
#         img_back = np.fft.ifft2(f_ishift)
#         result = np.real(img_back)
        
#         return result
    
#     # RepeatFactorWrapperë¥¼ ìœ„í•œ ë©”ì„œë“œë“¤
#     def set_epoch(self, epoch):
#         """RepeatFactorWrapper í˜¸í™˜ì„±"""
#         if hasattr(self, '_set_dataset_epoch'):
#             self._set_dataset_epoch(self, epoch)
    
#     @property
#     def epoch(self):
#         """RepeatFactorWrapper í˜¸í™˜ì„±"""
#         return getattr(self, '_epoch', 0)
    
#     @epoch.setter
#     def epoch(self, value):
#         """RepeatFactorWrapper í˜¸í™˜ì„±"""
#         self._epoch = value
    
#     def update_curriculum_stage(self, epoch):
#         """
#         ê¸°ì¡´ MedSAM2CurriculumDatasetê³¼ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤
#         Returns: bool (stageê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ ì—¬ë¶€)
#         """
#         # ìŠ¤í…Œì´ì§€ ê²°ì •
#         target_stage = "dense"
#         if epoch >= self.milestones.get("full", 50):
#             target_stage = "full"
#         elif epoch >= self.milestones.get("expand", 20):
#             target_stage = "expand"
        
#         # ì–‘ì ìƒíƒœ ì—…ë°ì´íŠ¸
#         old_state = self._quantum_state
#         if epoch < 10:
#             self._quantum_state = "ground"
#             self._coherence = 0.1
#         elif epoch < 25:
#             self._quantum_state = "excited"
#             self._coherence = 0.4
#         elif epoch < 40:
#             self._quantum_state = "coherent"
#             self._coherence = 0.7
#         else:
#             self._quantum_state = "resonant"
#             self._coherence = 0.9
        
#         # ìŠ¤í…Œì´ì§€ ë˜ëŠ” ì–‘ì ìƒíƒœ ë³€ê²½ í™•ì¸
#         stage_changed = target_stage != self.stage
#         quantum_state_changed = old_state != self._quantum_state
        
#         if stage_changed or quantum_state_changed:
#             self._load_stage_data(target_stage)
            
#             # repeat_factors ì—…ë°ì´íŠ¸
#             if self.samples:
#                 self.repeat_factors = torch.ones(len(self.samples))
#                 # ì–‘ì ìƒíƒœì— ë”°ë¥¸ ê°€ì¤‘ì¹˜ ì¡°ì •
#                 if self._quantum_state == "resonant":
#                     # ê³ ê¸‰ ë‹¨ê³„: ë³µì¡í•œ ìƒ˜í”Œì— ë” ë†’ì€ ê°€ì¤‘ì¹˜
#                     self.repeat_factors = self._calculate_quantum_weights()
            
#             logging.info(f"ğŸ”„ [QIR-CL] Stage: {self.stage.upper()} | "
#                         f"Quantum State: {self._quantum_state} | "
#                         f"Coherence: {self._coherence:.2f} | "
#                         f"Samples: {len(self.samples)}")
#             return True
        
#         return False
    
#     def _calculate_quantum_weights(self):
#         """ì–‘ì ê°€ì¤‘ì¹˜ ê³„ì‚°"""
#         if not self.samples:
#             return torch.ones(0)
        
#         weights = []
#         for sample in self.samples:
#             try:
#                 path = os.path.join(self.target_path, sample)
#                 data = np.load(path, allow_pickle=True)
#                 img = data['imgs'][0]
                
#                 # ì´ë¯¸ì§€ ì—”íŠ¸ë¡œí”¼ë¡œ ë³µì¡ë„ ì¶”ì •
#                 if img.ndim == 3:
#                     img = np.mean(img, axis=2)
                
#                 hist, _ = np.histogram(img.flatten(), bins=32)
#                 prob = hist / hist.sum()
#                 entropy = -np.sum(prob * np.log(prob + 1e-10))
                
#                 # ì—”íŠ¸ë¡œí”¼ê°€ ë†’ì„ìˆ˜ë¡ ë†’ì€ ê°€ì¤‘ì¹˜
#                 weight = 1.0 + 0.5 * (entropy / np.log(32))  # 1.0 ~ 1.5
#                 weights.append(weight)
#             except:
#                 weights.append(1.0)
        
#         return torch.tensor(weights, dtype=torch.float32)
    
#     def __len__(self):
#         return len(self.samples)
    
#     def __getitem__(self, idx):
#         if not self.samples:
#             return self._get_fallback_item(idx)
        
#         # ìƒ˜í”Œ ì¸ë±ìŠ¤ ì¡°ì •
#         sample_idx = idx % len(self.samples)
#         npz_name = self.samples[sample_idx]
#         npz_path = os.path.join(self.target_path, npz_name)
        
#         try:
#             data = np.load(npz_path, allow_pickle=True)
#             imgs = data['imgs']    # (T, H, W, 3)
#             masks = data['masks']  # (T, H, W)
            
#             # ì •ê·œí™”
#             if imgs.max() > 1.0:
#                 imgs = imgs.astype(np.float32) / 255.0
#             else:
#                 imgs = imgs.astype(np.float32)
            
#             masks = masks.astype(np.float32)
            
#             # ì–‘ì í–¥ìƒ ì ìš©
#             enhanced_imgs = []
#             for t in range(len(imgs)):
#                 enhanced = self._apply_quantum_enhancement(imgs[t])
#                 enhanced_imgs.append(enhanced)
            
#             enhanced_imgs = np.stack(enhanced_imgs, axis=0)
            
#             # ì°¨ì› ì¡°ì •: (T, H, W, 3) -> (T, 3, H, W)
#             if enhanced_imgs.ndim == 4 and enhanced_imgs.shape[-1] == 3:
#                 enhanced_imgs = enhanced_imgs.transpose(0, 3, 1, 2)
            
#             return {
#                 "video_id": npz_name.replace(".npz", ""),
#                 "images": torch.from_numpy(enhanced_imgs).float(),
#                 "masks": torch.from_numpy(masks).float(),
#                 "num_frames": len(imgs)
#             }
            
#         except Exception as e:
#             logging.error(f"âŒ [QIR-CL] Error loading {npz_path}: {e}")
#             # ë‹¤ìŒ ìƒ˜í”Œ ì‹œë„
#             next_idx = (sample_idx + 1) % len(self.samples)
#             return self.__getitem__(next_idx)
    
#     def _get_fallback_item(self, idx):
#         """ì—ëŸ¬ ì‹œ í´ë°± ì•„ì´í…œ"""
#         dummy_img = torch.zeros((1, 3, 256, 256))
#         dummy_mask = torch.zeros((1, 256, 256))
#         return {
#             "video_id": f"dummy_{idx}",
#             "images": dummy_img,
#             "masks": dummy_mask,
#             "num_frames": 1
#         }



#######################################################